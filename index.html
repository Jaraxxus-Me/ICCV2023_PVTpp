<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Simple Framework for End-to-End Predictive Visual Tracking">
  <meta name="keywords" content="Visual Object Tracking, Online, Latency-Aware Perception">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PVTpp</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->
  <link rel="icon" type="image/png" href="./static/images/airlab.png"> 
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/airlab.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://jaraxxus-me.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://ieeexplore.ieee.org/document/9561564">
            ADTrack - ICRA 2021
          </a>
          <a class="navbar-item" href="https://jaraxxus-me.github.io/ECCV2022_AirDet">
            AirDet - ECCV 2022
          </a>
          <a class="navbar-item" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cao_HiFT_Hierarchical_Feature_Transformer_for_Aerial_Tracking_ICCV_2021_paper.pdf">
            HiFT - ICCV 2021
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><img src="./static/images/clock.svg" width="80">PVT++&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</h1>
          <h1 class="title is-2 publication-title">A Simple Framework for End-to-End Predictive Visual Tracking</h1>
          <div class="column is-full_width">
            <h2 class="title is-4">ICCV 2023</h2>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jaraxxus-me.github.io/">Bowen Li</a><sup>1,*</sup>,</span>
            <span class="author-block">
              <a href="https://huang-ziyuan.github.io/">Ziyuan Huang</a><sup>2,*</sup>,</span>
            <span class="author-block">
              <a href="https://jay-ye.github.io/">Junjie Ye</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/yiming-li-58b519173/">Yiming Li</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="http://theairlab.org/team/sebastian/">Sebastian Scherer</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://hangzhaomit.github.io/">Hang Zhao</a><sup>5</sup>
            </span>
            <span class="author-block">
              <a href="https://www.researchgate.net/profile/Changhong-Fu">Changhong Fu</a><sup>3</sup>
            </span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2211.11629.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.11629"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Jaraxxus-Me/PVT_pp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/Jaraxxus-Me/AirDet"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://github.com/Jaraxxus-Me/AirDet_ROS"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-robot"></i>
                  </span>
                  <span>ROS</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://zhuanlan.zhihu.com/p/643835478"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-blog"></i>
                  </span>
                  <span>Blog</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop height="100%">
        <source src="./static/images/SUBT_video.mp4"
                type="video/mp4">
      </video>
      <!-- <img class="rounded" src="./media/nice-slam/teaser.png" > -->
      <br><br><br>
      <h2 class="subtitle has-text-centered">
      <strong>PVT++</strong> is motivated by onboard latency of visual trackers. By virtue of <b>end-to-end joint learning of motion and visual cues</b>, PVT++ works better than KFs.
    </h2>
    <!-- <h2 class="subtitle has-text-centered">
      (The <span style="color:#000000;">black</span> / <span style="color:#ff0000;">red</span> lines are the ground truth / predicted camera trajectory)
    </h2> -->
    
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <!-- Paper video. -->
        <!-- <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/V5hYTz5os0M?rel=0&amp;showinfo=0"
                      frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div> -->
        <!--/ Paper video. -->
      
    <!-- <br> -->
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Visual object tracking is essential to intelligent robots. 
            Most existing approaches have ignored the online latency that can cause severe performance degradation during real-world processing.
            Especially for unmanned aerial vehicles (UAVs), where robust tracking is more challenging and onboard computation is limited, the latency issue can be fatal.
          </p>
          <p>
            In this work, we present a simple framework for end-to-end latency-aware tracking, end-to-end predictive visual tracking (PVT++). 
            Unlike existing solutions that naively append Kalman Filters after trackers, PVT++ can be jointly optimized, so that it takes not only motion information but can also leverage the rich visual knowledge in most pre-trained tracker models for robust prediction.
          </p>
          <p>
            Besides, to bridge the training-evaluation domain gap, we propose a relative motion factor, empowering PVT++ to generalize to the challenging and complex UAV tracking scenes.
            These careful designs have made the small-capacity lightweight PVT++ a widely effective solution.
          </p>
          <p>
            Additionally, this work presents an extended latency-aware evaluation benchmark for assessing an <i>any-speed</i> tracker in the online setting. 
            Empirical results on a robotic platform from the aerial perspective show that PVT++ can achieve significant performance gain on various trackers and exhibit higher accuracy than prior solutions, largely mitigating the degradation brought by latency. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- <br> -->
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Contribution</h2>
        <div class="content has-text-justified">
          <li>
            We propose the first end-to-end general framework, PVT++, for latency-aware tracking, compensates for online latency by accurate motion prediction.
          </li>
          <li>
            We propose "<b>relative motion factor</b>", bridging the training-evaluation domain gap.
          </li>
          <li>
            We propose "<b>auxiliary branch</b>" and "<b>joint training</b>" techniques to effectively incorperate pre-exsiting visual features in prediction.
          </li>
          <li>
            We propose "<b>e-LAE</b>" to evaluate an <i>any-speed</i> tracker in the online setting.
          </li>
          <li>
            We conduct exhaustive experiments, using "<b>e-LAE</b>" to evaluate various SOTA trackers and validate PVT++ on several tracker models.
          </li>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full_width">
        <hr>
        <h2 class="title is-3">Method</h2>
        <br>
        <img src="static\images\method.svg" class="center"/>
        <div class="content has-text-justified">
          <br>  
          <p>
            The general framework of PVT++ (a) and e-LAE (b). 
          </p>
        </div>
      </div>
    </div>
    <hr>

    
    <!-- Applications.-->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full_width">
        <h2 class="title is-3">Qualitative&nbsp;&nbsp;Results</h2>
      </div>
    </div>
    <p>
      &nbsp
    </p>
    <h3 class="title is-4">Effect on Traditional Trackers</h3>
    <div class="column is-full_width">
      <img src="static\images\subt.svg" class="center"/>
      <div class="content has-text-justified">
        <br>  
        <p>
          The provided support images and examples of detection results in the real-world tests. AirDet is robust to distinct object scales and different illumination conditions.
        </p>
        </p>
      </div>
    </div>
    <p>
      &nbsp
    </p>
    <p>
      &nbsp
    </p>
    <h3 class="title is-4">Comparison with KF</h3>
    <div class="column is-full_width">
      <img src="static\images\deep_rpn.svg" class="center"/>
      <div class="content has-text-justified">
        <br>  
        <p>
          Compared with A-RPN, AirDet can better <em>notice</em> and <em>concentrate</em> on and novel object region, which leads to its more effective region proposals.
        </p>
        </p>
      </div>
    </div>
   
</div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{Li2023iccv,       
      author={Li, Bowen and Huang, Ziyuan and Ye, Junjie and Li, Yiming and Scherer, Sebastian and Zhao, Hang and Fu, Changhong},   
      booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, 
      title={{PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework}},
      year={2023},
      volume={},
      number={},
      pages={1-18}
    }</code></pre>
  </div>
</section>


<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    The work was done when Bowen Li and Pranay Reddy were interns at The Robotics Institute, CMU. The authors would like to thank all members of the Team Explorer for providing data collected from the DARPA Subterranean Challenge. Our code is built upon <a href="https://github.com/fanq15/FewX">FewX</a>, for which we sincerely express our gratitute to the authors.
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
